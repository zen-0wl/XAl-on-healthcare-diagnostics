{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=\"lightbeige\" size=+1.0><b>Data feature selection / extraction using SCI-XAI pipeline</b></font><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"bluegrey\" size=+1.0><b>Load and Read dataset</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "f_path = \"healthcare-dataset-stroke-data.csv\"\n",
    "df = pd.read_csv(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant features for post-stroke treatment plans\n",
    "selected_features = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'smoking_status']\n",
    "\n",
    "# Relevant columns\n",
    "df_selected = df[selected_features + ['stroke']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"bluegrey\" size=+1.0><b>Handling missing data</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics of Selected Features:\n",
      "               age  hypertension  heart_disease  avg_glucose_level  \\\n",
      "count  5110.000000   5110.000000    5110.000000        5110.000000   \n",
      "mean     43.226614      0.097456       0.054012         106.147677   \n",
      "std      22.612647      0.296607       0.226063          45.283560   \n",
      "min       0.080000      0.000000       0.000000          55.120000   \n",
      "25%      25.000000      0.000000       0.000000          77.245000   \n",
      "50%      45.000000      0.000000       0.000000          91.885000   \n",
      "75%      61.000000      0.000000       0.000000         114.090000   \n",
      "max      82.000000      1.000000       1.000000         271.740000   \n",
      "\n",
      "               bmi  \n",
      "count  4909.000000  \n",
      "mean     28.893237  \n",
      "std       7.854067  \n",
      "min      10.300000  \n",
      "25%      23.500000  \n",
      "50%      28.100000  \n",
      "75%      33.100000  \n",
      "max      97.600000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zen\\AppData\\Local\\Temp\\ipykernel_29324\\3162270261.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['bmi'].replace('N/A', pd.NA, inplace=True)\n",
      "C:\\Users\\zen\\AppData\\Local\\Temp\\ipykernel_29324\\3162270261.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['bmi'] = pd.to_numeric(df_selected['bmi'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Replace 'N/A' with pd.NA for proper handling\n",
    "df_selected['bmi'].replace('N/A', pd.NA, inplace=True)  \n",
    "# Convert 'bmi' to numeric \n",
    "df_selected['bmi'] = pd.to_numeric(df_selected['bmi'], errors='coerce')  \n",
    "\n",
    "print(\"Summary Statistics of Selected Features:\")\n",
    "print(df_selected[selected_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"bluegrey\" size=+1.0><b>SCI-XAI pipeline and feature selection</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "X = pd.get_dummies(df_selected[selected_features], columns=['smoking_status'])  # One-hot encode 'smoking_status'\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean') \n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "y = df_selected['stroke']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Selection using Gradient Boosting for stroke prediction\n",
    "model_gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "model_gradient_boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"bluegrey\" size=+1.0><b>Data exploration</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'smoking_status']\n",
      "               age  hypertension  heart_disease  avg_glucose_level  \\\n",
      "count  5110.000000   5110.000000    5110.000000        5110.000000   \n",
      "mean     43.226614      0.097456       0.054012         106.147677   \n",
      "std      22.612647      0.296607       0.226063          45.283560   \n",
      "min       0.080000      0.000000       0.000000          55.120000   \n",
      "25%      25.000000      0.000000       0.000000          77.245000   \n",
      "50%      45.000000      0.000000       0.000000          91.885000   \n",
      "75%      61.000000      0.000000       0.000000         114.090000   \n",
      "max      82.000000      1.000000       1.000000         271.740000   \n",
      "\n",
      "               bmi  \n",
      "count  4909.000000  \n",
      "mean     28.893237  \n",
      "std       7.854067  \n",
      "min      10.300000  \n",
      "25%      23.500000  \n",
      "50%      28.100000  \n",
      "75%      33.100000  \n",
      "max      97.600000  \n"
     ]
    }
   ],
   "source": [
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Display summary statistics of the selected features\n",
    "print(df[selected_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"bluegrey\" size=+1.0><b>XAI techniques - Eli5, LIME, and SHAP</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'if_delegate_has_method' from 'sklearn.utils.metaestimators' (c:\\Users\\zen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lime_tabular\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\eli5\\__init__.py:13\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformatters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     format_as_html,\n\u001b[0;32m      8\u001b[0m     format_html_styles,\n\u001b[0;32m      9\u001b[0m     format_as_text,\n\u001b[0;32m     10\u001b[0m     format_as_dict,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain_weights, explain_prediction\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain_weights_sklearn, explain_prediction_sklearn\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transform_feature_names\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\eli5\\sklearn\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain_weights\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     explain_weights_sklearn,\n\u001b[0;32m      5\u001b[0m     explain_linear_classifier_weights,\n\u001b[0;32m      6\u001b[0m     explain_linear_regressor_weights,\n\u001b[0;32m      7\u001b[0m     explain_rf_feature_importance,\n\u001b[0;32m      8\u001b[0m     explain_decision_tree,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain_prediction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     explain_prediction_sklearn,\n\u001b[0;32m     12\u001b[0m     explain_prediction_linear_classifier,\n\u001b[0;32m     13\u001b[0m     explain_prediction_linear_regressor,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     InvertableHashingVectorizer,\n\u001b[0;32m     17\u001b[0m     FeatureUnhasher,\n\u001b[0;32m     18\u001b[0m     invert_hashing_and_fit,\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\eli5\\sklearn\\explain_weights.py:78\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transform_feature_names\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_feature_importances\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     75\u001b[0m     get_feature_importances_filtered,\n\u001b[0;32m     76\u001b[0m     get_feature_importance_explanation,\n\u001b[0;32m     77\u001b[0m )\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpermutation_importance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PermutationImportance\n\u001b[0;32m     81\u001b[0m LINEAR_CAVEATS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124mCaveats:\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124m1. Be careful with features which are not\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124m   classification result for most examples.\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mlstrip()\n\u001b[0;32m     93\u001b[0m HASHING_CAVEATS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124mFeature names are restored from their hashes; this is not 100\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m precise\u001b[39m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124mbecause collisions are possible. For known collisions possible feature names\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124mthe result is positive.\u001b[39m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mlstrip()\n",
      "File \u001b[1;32mc:\\Users\\zen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\eli5\\sklearn\\permutation_importance.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_cv\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m if_delegate_has_method\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_array, check_random_state\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     BaseEstimator,\n\u001b[0;32m     11\u001b[0m     MetaEstimatorMixin,\n\u001b[0;32m     12\u001b[0m     clone,\n\u001b[0;32m     13\u001b[0m     is_classifier\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'if_delegate_has_method' from 'sklearn.utils.metaestimators' (c:\\Users\\zen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py)"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gradient Boosting model trained on dataset\n",
    "model_stroke = model_gradient_boosting\n",
    "\n",
    "# X_train_stroke and y_train_stroke as stroke prediction dataset\n",
    "X_train_stroke, X_test_stroke, y_train_stroke, y_test_stroke = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Eli5 for stroke prediction\n",
    "explainability_stroke = eli5.show_weights(model_stroke, feature_names=selected_features)\n",
    "\n",
    "# Apply LIME for stroke prediction\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer(X_train_stroke.values, mode='classification', feature_names=selected_features)\n",
    "instance_to_explain = X_test_stroke.iloc[0]\n",
    "lime_explanation = lime_explainer.explain_instance(instance_to_explain.values, model_stroke.predict_proba)\n",
    "\n",
    "# Explores advanced local surrogate methods i.e SHAP for feature importance analysis\n",
    "explainer = shap.TreeExplainer(model_stroke)\n",
    "shap_values = explainer.shap_values(X_test_stroke)\n",
    "\n",
    "# Feature importance plot using SHAP\n",
    "shap.summary_plot(shap_values, X_test_stroke, feature_names=selected_features)\n",
    "\n",
    "# Visualize specific instance using SHAP\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0, :], instance_to_explain, feature_names=selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
