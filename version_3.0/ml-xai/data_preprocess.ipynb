{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n",
      "None\n",
      "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
      "0   9046    Male  67.0             0              1          Yes   \n",
      "1  51676  Female  61.0             0              0          Yes   \n",
      "2  31112    Male  80.0             0              1          Yes   \n",
      "3  60182  Female  49.0             0              0          Yes   \n",
      "4   1665  Female  79.0             1              0          Yes   \n",
      "\n",
      "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
      "0        Private          Urban             228.69  36.6  formerly smoked   \n",
      "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
      "2        Private          Rural             105.92  32.5     never smoked   \n",
      "3        Private          Urban             171.23  34.4           smokes   \n",
      "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
      "\n",
      "   stroke  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/zen/Documents/-- four/s2/FYP I/XAl-on-healthcare-diagnostics/version_3.0/healthcare-dataset-stroke-data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"bluegrey\" size=+1.0><b>Preprocess</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training Data Shape: (4087, 19)\n",
      "Processed Testing Data Shape: (1022, 19)\n",
      "Original Class Distribution:\n",
      "stroke\n",
      "0    3900\n",
      "1     187\n",
      "Name: count, dtype: int64\n",
      "Resampled Class Distribution:\n",
      "stroke\n",
      "1    3655\n",
      "0    3261\n",
      "Name: count, dtype: int64\n",
      "Resampled Training Data Shape: (6916, 19)\n"
     ]
    }
   ],
   "source": [
    "data['bmi'] = data['bmi'].fillna(data['bmi'].mean())\n",
    "\n",
    "# BMI into categorical values\n",
    "def categorize_bmi(row):\n",
    "    bmi = row['bmi']\n",
    "    age = row['age']\n",
    "    \n",
    "    if pd.isnull(bmi):\n",
    "        return 'Unknown'\n",
    "    if age < 20:\n",
    "        return 'Child'\n",
    "    elif bmi <= 18.5:\n",
    "        return 'Underweight'\n",
    "    elif 18.5 < bmi <= 25:\n",
    "        return 'Normal weight'\n",
    "    elif 25 < bmi <= 30:\n",
    "        return 'Overweight'\n",
    "    elif bmi > 30:\n",
    "        return 'Obese'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "data['bmi_category'] = data.apply(categorize_bmi, axis=1)\n",
    "\n",
    "# Drop original numerical bmi column\n",
    "data.drop(columns=['bmi'], inplace=True)\n",
    "\n",
    "# Remove rare gender outlier\n",
    "data.drop(data[data['gender'] == 'Other'].index[0], inplace=True)\n",
    "\n",
    "# Drop unnecessary ID column\n",
    "data.drop(columns=['id'], inplace=True)\n",
    "\n",
    "data.loc[(data['smoking_status'] == 'Unknown') & (data['age'] <= 12), 'smoking_status'] = 'never smoked'\n",
    "\n",
    "# === Map binary variables ===\n",
    "data['gender'] = data['gender'].map({'Male': 1, 'Female': 0})\n",
    "data['ever_married'] = data['ever_married'].map({'Yes': 1, 'No': 0})\n",
    "data['Residence_type'] = data['Residence_type'].map({'Urban': 1, 'Rural': 0})\n",
    "\n",
    "# === Normalize category strings ===\n",
    "data['work_type'] = data['work_type'].map({\n",
    "    'Private': 'private',\n",
    "    'Self-employed': 'self_employed',\n",
    "    'Govt_job': 'govt_job',\n",
    "    'Never_worked': 'never_worked',\n",
    "    'children': 'children'\n",
    "})\n",
    "data['smoking_status'] = data['smoking_status'].map({\n",
    "    'formerly smoked': 'formerly_smoked',\n",
    "    'never smoked': 'never_smoked',\n",
    "    'Unknown': 'unknown'\n",
    "})\n",
    "# (bmi_category already cleaned above)\n",
    "\n",
    "# === Define features and target ===\n",
    "target_column = 'stroke'\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# === Define column types ===\n",
    "categorical_columns = ['work_type', 'smoking_status', 'bmi_category']\n",
    "numerical_columns = ['age', 'avg_glucose_level', 'gender', 'ever_married', 'Residence_type']\n",
    "\n",
    "def preprocess_data(X_train, X_test, categorical_columns, numerical_columns):\n",
    "    \"\"\"\n",
    "    Apply preprocessing pipeline to the training and testing data.\n",
    "\n",
    "    Args:\n",
    "    - X_train: The training feature data.\n",
    "    - X_test: The testing feature data.\n",
    "    - categorical_columns: List of categorical columns to be one-hot encoded.\n",
    "    - numerical_columns: List of numerical columns to be scaled.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_processed: Preprocessed training data.\n",
    "    - X_test_processed: Preprocessed testing data.\n",
    "    \"\"\"\n",
    "    # Set up a column transformer for preprocessing\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_columns),  # Scale numerical columns\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)  # Encode categorical columns\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    X_train_processed = pipeline.fit_transform(X_train)\n",
    "    X_test_processed = pipeline.transform(X_test)\n",
    "\n",
    "    print(f\"Processed Training Data Shape: {X_train_processed.shape}\")\n",
    "    print(f\"Processed Testing Data Shape: {X_test_processed.shape}\")\n",
    "    \n",
    "    return X_train_processed, X_test_processed, pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_processed, X_test_processed, pipeline = preprocess_data(X_train, X_test, categorical_columns, numerical_columns)\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# Show class distribution\n",
    "print(f\"Original Class Distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"Resampled Class Distribution:\\n{pd.Series(y_train_resampled).value_counts()}\")\n",
    "print(f\"Resampled Training Data Shape: {X_train_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_columns) # categorical features names\n",
    "\n",
    "# Combine with numerical column names (these stay as-is through StandardScaler)\n",
    "all_features = numerical_columns + list(cat_features)\n",
    "\n",
    "# Training set\n",
    "resampled_data = pd.DataFrame(X_train_resampled, columns=all_features)\n",
    "resampled_data['stroke'] = y_train_resampled\n",
    "resampled_data.to_csv('resamp_training_data.csv', index=False)\n",
    "\n",
    "# Test set\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=all_features)\n",
    "X_test_df['stroke'] = y_test.values\n",
    "X_test_df.to_csv('resamp_test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
