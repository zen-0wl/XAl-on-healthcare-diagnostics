{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n",
      "None\n",
      "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
      "0   9046    Male  67.0             0              1          Yes   \n",
      "1  51676  Female  61.0             0              0          Yes   \n",
      "2  31112    Male  80.0             0              1          Yes   \n",
      "3  60182  Female  49.0             0              0          Yes   \n",
      "4   1665  Female  79.0             1              0          Yes   \n",
      "\n",
      "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
      "0        Private          Urban             228.69  36.6  formerly smoked   \n",
      "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
      "2        Private          Rural             105.92  32.5     never smoked   \n",
      "3        Private          Urban             171.23  34.4           smokes   \n",
      "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
      "\n",
      "   stroke  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/zen/Documents/-- four/s2/FYP I/XAl-on-healthcare-diagnostics/version_3.0/healthcare-dataset-stroke-data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"bluegrey\" size=+1.0><b>Preprocess</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training Data Shape: (4088, 18)\n",
      "Processed Testing Data Shape: (1022, 18)\n"
     ]
    }
   ],
   "source": [
    "data['bmi'] = data['bmi'].fillna(data['bmi'].mean())\n",
    "\n",
    "data = data.drop(columns=['id'])\n",
    "\n",
    "target_column = 'stroke'\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "def preprocess_data(X_train, X_test, categorical_columns, numerical_columns):\n",
    "    \"\"\"\n",
    "    Apply preprocessing pipeline to the training and testing data.\n",
    "\n",
    "    Args:\n",
    "    - X_train: The training feature data.\n",
    "    - X_test: The testing feature data.\n",
    "    - categorical_columns: List of categorical columns to be one-hot encoded.\n",
    "    - numerical_columns: List of numerical columns to be scaled.\n",
    "\n",
    "    Returns:\n",
    "    - X_train_processed: Preprocessed training data.\n",
    "    - X_test_processed: Preprocessed testing data.\n",
    "    \"\"\"\n",
    "    # Set up a column transformer for preprocessing\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_columns),  # Scale numerical columns\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)  # Encode categorical columns\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    X_train_processed = pipeline.fit_transform(X_train)\n",
    "    X_test_processed = pipeline.transform(X_test)\n",
    "\n",
    "    print(f\"Processed Training Data Shape: {X_train_processed.shape}\")\n",
    "    print(f\"Processed Testing Data Shape: {X_test_processed.shape}\")\n",
    "    \n",
    "    return X_train_processed, X_test_processed, pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "numerical_columns = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "X_train_processed, X_test_processed, pipeline = preprocess_data(X_train, X_test, categorical_columns, numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to 'processed_stroke_data_train.csv'\n"
     ]
    }
   ],
   "source": [
    "processed_features = pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_columns)\n",
    "\n",
    "all_features = list(numerical_columns) + list(processed_features)\n",
    "\n",
    "processed_data_train = pd.DataFrame(X_train_processed, columns=all_features)\n",
    "processed_data_train['stroke'] = y_train.values\n",
    "processed_data_train.to_csv('processed_stroke_data_train.csv', index=False)\n",
    "print(\"Processed data saved to 'processed_stroke_data_train.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed test data saved to 'processed_stroke_data_test.csv'\n"
     ]
    }
   ],
   "source": [
    "processed_features_test = pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_columns)\n",
    "\n",
    "all_features_test = list(numerical_columns) + list(processed_features_test)\n",
    "\n",
    "# Create df for the test data\n",
    "processed_data_test = pd.DataFrame(X_test_processed, columns=all_features_test)\n",
    "processed_data_test['stroke'] = y_test.values\n",
    "\n",
    "# Save the processed test data to a CSV file\n",
    "processed_data_test.to_csv('processed_stroke_data_test.csv', index=False)\n",
    "print(\"Processed test data saved to 'processed_stroke_data_test.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
